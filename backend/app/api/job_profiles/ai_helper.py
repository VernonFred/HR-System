"""å²—ä½ç”»åƒ - AIè¾…åŠ©æœåŠ¡ V5.

åŠŸèƒ½ï¼š
1. åˆ†æä¼˜ç§€å‘˜å·¥ç®€å†ï¼Œç”Ÿæˆå²—ä½ç”»åƒé…ç½®å»ºè®®
2. åˆ†æ JD æ–‡æœ¬ï¼Œç”Ÿæˆå²—ä½ç”»åƒé…ç½®å»ºè®®

å®šä½ï¼šè¾…åŠ©å·¥å…·ï¼Œä¸å­˜å‚¨ç®€å†æ•°æ®

V5 æ›´æ–°ï¼š
- ä½¿ç”¨ ModelScope Pro (32B) æ¨¡å‹
- ä½¿ç”¨æ–°çš„ V5 æç¤ºè¯
"""

import logging
from typing import Dict, List, Any, Optional

from app.core.ai.ai_client import AIClientError, pick_content_text, parse_json_safely
from app.core.ai.portrait_router import call_portrait_model
from app.core.ai.prompt_builder import (
    build_job_resume_analysis_prompt,
    build_job_jd_analysis_prompt,
)

logger = logging.getLogger(__name__)


async def analyze_resume_for_job_profile(
    resume_text: str,
    job_title: str,
    department: Optional[str] = None
) -> Dict[str, Any]:
    """
    åˆ†æä¼˜ç§€å‘˜å·¥ç®€å†ï¼Œç”Ÿæˆå²—ä½ç”»åƒé…ç½®å»ºè®® - V5 ç‰ˆæœ¬.
    
    Args:
        resume_text: ç®€å†æ–‡æœ¬å†…å®¹
        job_title: å²—ä½åç§°
        department: éƒ¨é—¨åç§°ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        å²—ä½ç”»åƒé…ç½®å»ºè®®
    """
    # ä½¿ç”¨ V5 æç¤ºè¯
    messages = build_job_resume_analysis_prompt(resume_text, job_title, department)
    
    try:
        # V5: ä½¿ç”¨ ModelScope Pro (32B) æ¨¡å‹
        logger.info(f"ğŸ¯ å²—ä½ç”»åƒ-ç®€å†åˆ†æ: {job_title}")
        print(f"ğŸ¯ å²—ä½ç”»åƒ-ç®€å†åˆ†æ: {job_title}")
        
        response = await call_portrait_model(
            messages=messages,
            level="pro",  # ä½¿ç”¨ 32B æ¨¡å‹
            max_tokens=2048,
            temperature=0.4,
        )
        
        # è§£æå“åº”
        content = response.get("choices", [{}])[0].get("message", {}).get("content", "")
        data = parse_json_safely(content)
        
        # å¡«å……é»˜è®¤å€¼
        result = _fill_defaults(data, job_title, department)
        
        logger.info(
            "âœ… AIåˆ†æç®€å†æˆåŠŸ: job_title=%s, dimensions=%d",
            job_title,
            len(result.get("dimensions", []))
        )
        print(f"âœ… AIåˆ†æç®€å†æˆåŠŸ: {job_title}, {len(result.get('dimensions', []))} ä¸ªç»´åº¦")
        
        return result
        
    except Exception as e:
        logger.error("âŒ AIåˆ†æç®€å†å¤±è´¥: %s", e, exc_info=True)
        print(f"âŒ AIåˆ†æç®€å†å¤±è´¥: {e}")
        # é™çº§åˆ°è§„åˆ™åŒ–åˆ†æ
        return _fallback_analysis(resume_text, job_title, department)


async def analyze_jd_for_job_profile(
    jd_text: str,
    job_title: str,
    department: Optional[str] = None
) -> Dict[str, Any]:
    """
    åˆ†æ JD æ–‡æœ¬ï¼Œç”Ÿæˆå²—ä½ç”»åƒé…ç½®å»ºè®® - V5 ç‰ˆæœ¬.
    
    Args:
        jd_text: JDï¼ˆå²—ä½æè¿°ï¼‰æ–‡æœ¬
        job_title: å²—ä½åç§°
        department: éƒ¨é—¨åç§°
        
    Returns:
        å²—ä½ç”»åƒé…ç½®å»ºè®®
    """
    # ä½¿ç”¨ V5 æç¤ºè¯
    messages = build_job_jd_analysis_prompt(jd_text, job_title, department)
    
    try:
        # V5: ä½¿ç”¨ ModelScope Pro (32B) æ¨¡å‹
        logger.info(f"ğŸ¯ å²—ä½ç”»åƒ-JDåˆ†æ: {job_title}")
        print(f"ğŸ¯ å²—ä½ç”»åƒ-JDåˆ†æ: {job_title}")
        
        response = await call_portrait_model(
            messages=messages,
            level="pro",  # ä½¿ç”¨ 32B æ¨¡å‹
            max_tokens=2048,
            temperature=0.4,
        )
        
        # è§£æå“åº”
        content = response.get("choices", [{}])[0].get("message", {}).get("content", "")
        data = parse_json_safely(content)
        
        # å¡«å……é»˜è®¤å€¼
        result = _fill_defaults(data, job_title, department)
        
        logger.info("âœ… AIåˆ†æJDæˆåŠŸ: job_title=%s", job_title)
        print(f"âœ… AIåˆ†æJDæˆåŠŸ: {job_title}")
        
        return result
        
    except Exception as e:
        logger.error("âŒ AIåˆ†æJDå¤±è´¥: %s", e, exc_info=True)
        print(f"âŒ AIåˆ†æJDå¤±è´¥: {e}")
        return _fallback_analysis(jd_text, job_title, department)


def _fill_defaults(data: Dict[str, Any], job_title: str, department: Optional[str]) -> Dict[str, Any]:
    """å¡«å……é»˜è®¤å€¼å¹¶è§„èŒƒåŒ–è¾“å‡º."""
    result = {
        "name": data.get("name") or job_title,
        "department": data.get("department") or department or "æœªçŸ¥éƒ¨é—¨",
        "description": data.get("description") or f"{job_title}å²—ä½èƒ½åŠ›è¦æ±‚",
        "tags": data.get("tags") or [],
        "dimensions": data.get("dimensions") or [],
        "analysis": data.get("analysis") or "AIåˆ†æå®Œæˆ"
    }
    
    # éªŒè¯ç»´åº¦æƒé‡
    dimensions = result["dimensions"]
    if dimensions:
        total_weight = sum(d.get("weight", 0) for d in dimensions)
        
        # å¦‚æœæƒé‡ä¸æ˜¯100ï¼Œè‡ªåŠ¨å½’ä¸€åŒ–
        if total_weight != 100 and total_weight > 0:
            for dim in dimensions:
                dim["weight"] = round(dim.get("weight", 0) * 100 / total_weight, 1)
    
    # ç¡®ä¿ tags æ˜¯åˆ—è¡¨
    if isinstance(result["tags"], str):
        result["tags"] = [t.strip() for t in result["tags"].split(",") if t.strip()]
    
    return result


def _fallback_analysis(
    text: str,
    job_title: str,
    department: Optional[str]
) -> Dict[str, Any]:
    """é™çº§åˆ†æ - ä½¿ç”¨è§„åˆ™åŒ–æ–¹æ³•ç”ŸæˆåŸºç¡€é…ç½®."""
    
    logger.info("ä½¿ç”¨é™çº§åˆ†ææ–¹æ¡ˆ: %s", job_title)
    
    # åŸºç¡€èƒ½åŠ›ç»´åº¦æ¨¡æ¿
    default_dimensions = [
        {"name": "ä¸“ä¸šæŠ€èƒ½", "weight": 30, "description": f"{job_title}æ‰€éœ€çš„æ ¸å¿ƒä¸“ä¸šæŠ€èƒ½"},
        {"name": "æ²Ÿé€šåä½œ", "weight": 20, "description": "å›¢é˜Ÿåä½œä¸è·¨éƒ¨é—¨æ²Ÿé€šèƒ½åŠ›"},
        {"name": "å­¦ä¹ èƒ½åŠ›", "weight": 20, "description": "å¿«é€Ÿå­¦ä¹ æ–°çŸ¥è¯†å’Œé€‚åº”å˜åŒ–çš„èƒ½åŠ›"},
        {"name": "é—®é¢˜è§£å†³", "weight": 15, "description": "åˆ†æé—®é¢˜å’Œè§£å†³é—®é¢˜çš„èƒ½åŠ›"},
        {"name": "è´£ä»»å¿ƒ", "weight": 15, "description": "å·¥ä½œæ€åº¦å’Œè´£ä»»æ‹…å½“"},
    ]
    
    # ç®€å•çš„æ ‡ç­¾æå–
    tags = _extract_tags(text)
    
    return {
        "name": job_title,
        "department": department or "æœªçŸ¥éƒ¨é—¨",
        "description": f"{job_title}å²—ä½ï¼Œéœ€è¦å…·å¤‡ç›¸å…³ä¸“ä¸šæŠ€èƒ½å’Œè‰¯å¥½çš„å›¢é˜Ÿåä½œèƒ½åŠ›ã€‚",
        "tags": tags[:6],  # æœ€å¤š6ä¸ªæ ‡ç­¾
        "dimensions": default_dimensions,
        "analysis": "åŸºäºè§„åˆ™åŒ–åˆ†æç”Ÿæˆçš„åŸºç¡€é…ç½®ï¼Œå»ºè®®æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ç»´åº¦æƒé‡ã€‚"
    }


def _extract_tags(text: str) -> List[str]:
    """ä»æ–‡æœ¬ä¸­æå–æ ‡ç­¾."""
    
    # å¸¸è§æŠ€èƒ½å’Œç‰¹è´¨å…³é”®è¯
    keywords_map = {
        "æ²Ÿé€š": "æ²Ÿé€šèƒ½åŠ›",
        "åè°ƒ": "åè°ƒèƒ½åŠ›",
        "ç®¡ç†": "ç®¡ç†èƒ½åŠ›",
        "åˆ†æ": "åˆ†æèƒ½åŠ›",
        "åˆ›æ–°": "åˆ›æ–°æ€ç»´",
        "å›¢é˜Ÿ": "å›¢é˜Ÿåä½œ",
        "æ‰§è¡Œ": "æ‰§è¡ŒåŠ›",
        "é¢†å¯¼": "é¢†å¯¼åŠ›",
        "ç­–åˆ’": "ç­–åˆ’èƒ½åŠ›",
        "è®¾è®¡": "è®¾è®¡èƒ½åŠ›",
        "å¼€å‘": "å¼€å‘èƒ½åŠ›",
        "è¿è¥": "è¿è¥èƒ½åŠ›",
        "é”€å”®": "é”€å”®èƒ½åŠ›",
        "å®¢æˆ·": "å®¢æˆ·å¯¼å‘",
        "æ•°æ®": "æ•°æ®åˆ†æ",
        "é¡¹ç›®": "é¡¹ç›®ç®¡ç†",
        "äº§å“": "äº§å“æ€ç»´",
        "æŠ€æœ¯": "æŠ€æœ¯èƒ½åŠ›",
        "ä¸šåŠ¡": "ä¸šåŠ¡ç†è§£",
        "æŠ—å‹": "æŠ—å‹èƒ½åŠ›",
    }
    
    tags = []
    for keyword, tag in keywords_map.items():
        if keyword in text and tag not in tags:
            tags.append(tag)
    
    return tags[:8]  # æœ€å¤š8ä¸ªæ ‡ç­¾


async def configure_job_dimensions(
    job_title: str,
    description: Optional[str] = None,
    existing_dimensions: Optional[List[Dict]] = None
) -> Dict[str, Any]:
    """
    AIæ™ºèƒ½é…ç½®å²—ä½èƒ½åŠ›ç»´åº¦å’Œæƒé‡.
    
    Args:
        job_title: å²—ä½åç§°
        description: å²—ä½æè¿°ï¼ˆå¯é€‰ï¼‰
        existing_dimensions: å·²æœ‰çš„ç»´åº¦åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        é…ç½®å¥½çš„ç»´åº¦åˆ—è¡¨å’Œåˆ†æè¯´æ˜
    """
    has_existing = existing_dimensions and len(existing_dimensions) > 0
    
    # æ„å»ºæç¤ºè¯
    if has_existing:
        # åœºæ™¯1ï¼šå·²æœ‰ç»´åº¦ï¼Œæ™ºèƒ½åˆ†é…æƒé‡
        dim_list = "\n".join([
            f"- {d.get('name', 'æœªå‘½å')}: {d.get('description', 'æ— æè¿°')}"
            for d in existing_dimensions
        ])
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„äººåŠ›èµ„æºä¸“å®¶ï¼Œè¯·ä¸º"{job_title}"å²—ä½çš„èƒ½åŠ›ç»´åº¦æ™ºèƒ½åˆ†é…æƒé‡ã€‚

å²—ä½æè¿°ï¼š{description or 'æ— '}

å·²æœ‰çš„èƒ½åŠ›ç»´åº¦ï¼š
{dim_list}

è¯·æ ¹æ®ä»¥ä¸‹åŸåˆ™åˆ†é…æƒé‡ï¼š
1. æƒé‡æ€»å’Œå¿…é¡»ç­‰äº100
2. æ ¹æ®å²—ä½ç‰¹ç‚¹ï¼Œæ ¸å¿ƒèƒ½åŠ›æƒé‡åº”è¯¥æ›´é«˜
3. è€ƒè™‘èƒ½åŠ›ç»´åº¦ä¹‹é—´çš„å…³è”æ€§å’Œé‡è¦æ€§å·®å¼‚
4. æƒé‡åˆ†é…è¦æœ‰åŒºåˆ†åº¦ï¼Œé¿å…å¹³å‡åˆ†é…

è¯·è¾“å‡ºJSONæ ¼å¼ï¼š
{{
  "dimensions": [
    {{"name": "ç»´åº¦åç§°", "weight": æƒé‡æ•°å€¼, "description": "ç»´åº¦æè¿°"}}
  ],
  "analysis": "æƒé‡åˆ†é…çš„è€ƒé‡è¯´æ˜ï¼ˆ50å­—ä»¥å†…ï¼‰"
}}"""
    else:
        # åœºæ™¯2ï¼šå…¨æ–°é…ç½®ï¼Œç”Ÿæˆç»´åº¦å’Œæƒé‡
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„äººåŠ›èµ„æºä¸“å®¶ï¼Œè¯·ä¸º"{job_title}"å²—ä½è®¾è®¡èƒ½åŠ›æ¨¡å‹ã€‚

å²—ä½æè¿°ï¼š{description or 'æ— '}

è¯·æ ¹æ®ä»¥ä¸‹åŸåˆ™è®¾è®¡èƒ½åŠ›ç»´åº¦ï¼š
1. è®¾è®¡4-6ä¸ªæ ¸å¿ƒèƒ½åŠ›ç»´åº¦
2. æƒé‡æ€»å’Œå¿…é¡»ç­‰äº100
3. ç»´åº¦è¦å…·ä½“ã€å¯è¡¡é‡ï¼Œé¿å…è¿‡äºæŠ½è±¡
4. æ ¸å¿ƒèƒ½åŠ›æƒé‡åº”è¯¥æ›´é«˜ï¼ˆ25-35ï¼‰ï¼Œæ¬¡è¦èƒ½åŠ›é€‚ä¸­ï¼ˆ15-25ï¼‰ï¼Œè¾…åŠ©èƒ½åŠ›è¾ƒä½ï¼ˆ5-15ï¼‰
5. æ¯ä¸ªç»´åº¦éœ€è¦æœ‰æ¸…æ™°çš„æè¿°

å²—ä½ç±»å‹å‚è€ƒï¼š
- æŠ€æœ¯ç±»ï¼šä¸“ä¸šæŠ€èƒ½ã€é—®é¢˜è§£å†³ã€å­¦ä¹ èƒ½åŠ›ã€ä»£ç è´¨é‡ã€å›¢é˜Ÿåä½œ
- ç®¡ç†ç±»ï¼šé¢†å¯¼åŠ›ã€æˆ˜ç•¥æ€ç»´ã€å›¢é˜Ÿç®¡ç†ã€æ²Ÿé€šåè°ƒã€å†³ç­–èƒ½åŠ›
- é”€å”®ç±»ï¼šå®¢æˆ·å¼€å‘ã€è°ˆåˆ¤èƒ½åŠ›ã€ç›®æ ‡å¯¼å‘ã€æŠ—å‹èƒ½åŠ›ã€å¸‚åœºæ´å¯Ÿ
- è¡Œæ”¿ç±»ï¼šæ‰§è¡ŒåŠ›ã€ç»†èŠ‚æŠŠæ§ã€æµç¨‹ç®¡ç†ã€æ²Ÿé€šåè°ƒã€æœåŠ¡æ„è¯†
- äººäº‹ç±»ï¼šäººæ‰è¯†åˆ«ã€æ²Ÿé€šèƒ½åŠ›ã€åˆ¶åº¦å»ºè®¾ã€å‘˜å·¥å…³ç³»ã€æˆ˜ç•¥æ€ç»´

è¯·è¾“å‡ºJSONæ ¼å¼ï¼š
{{
  "dimensions": [
    {{"name": "ç»´åº¦åç§°", "weight": æƒé‡æ•°å€¼, "description": "ç»´åº¦æè¿°ï¼ˆ20-40å­—ï¼‰"}}
  ],
  "analysis": "èƒ½åŠ›æ¨¡å‹è®¾è®¡è¯´æ˜ï¼ˆ50å­—ä»¥å†…ï¼‰"
}}"""

    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„äººåŠ›èµ„æºé¡¾é—®ï¼Œæ“…é•¿è®¾è®¡å²—ä½èƒ½åŠ›æ¨¡å‹ã€‚è¯·ç›´æ¥è¾“å‡ºJSONï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚"},
        {"role": "user", "content": prompt}
    ]
    
    try:
        logger.info(f"ğŸ¯ AIé…ç½®èƒ½åŠ›ç»´åº¦: {job_title}")
        
        response = await call_portrait_model(
            messages=messages,
            level="pro",
            max_tokens=1024,
            temperature=0.3,
        )
        
        content = response.get("choices", [{}])[0].get("message", {}).get("content", "")
        data = parse_json_safely(content)
        
        # éªŒè¯å’Œä¿®æ­£æƒé‡
        dimensions = data.get("dimensions", [])
        if dimensions:
            total = sum(d.get("weight", 0) for d in dimensions)
            if total != 100 and total > 0:
                # å½’ä¸€åŒ–æƒé‡
                for d in dimensions:
                    d["weight"] = round(d.get("weight", 0) * 100 / total)
                # å¤„ç†èˆå…¥è¯¯å·®
                diff = 100 - sum(d["weight"] for d in dimensions)
                if diff != 0:
                    dimensions[0]["weight"] += diff
        
        logger.info(f"âœ… AIé…ç½®å®Œæˆ: {job_title}, {len(dimensions)} ä¸ªç»´åº¦")
        
        return {
            "dimensions": dimensions,
            "analysis": data.get("analysis", "AIé…ç½®å®Œæˆ")
        }
        
    except Exception as e:
        logger.error("âŒ AIé…ç½®ç»´åº¦å¤±è´¥: %s", e, exc_info=True)
        # é™çº§å¤„ç†
        return _fallback_dimension_config(job_title, existing_dimensions)


def _fallback_dimension_config(
    job_title: str,
    existing_dimensions: Optional[List[Dict]] = None
) -> Dict[str, Any]:
    """é™çº§å¤„ç† - è§„åˆ™åŒ–é…ç½®ç»´åº¦."""
    
    if existing_dimensions and len(existing_dimensions) > 0:
        # å·²æœ‰ç»´åº¦ï¼Œå‡åˆ†æƒé‡
        count = len(existing_dimensions)
        base_weight = 100 // count
        remainder = 100 % count
        
        dimensions = []
        for i, d in enumerate(existing_dimensions):
            dimensions.append({
                "name": d.get("name", f"ç»´åº¦{i+1}"),
                "weight": base_weight + (1 if i < remainder else 0),
                "description": d.get("description", "")
            })
        
        return {
            "dimensions": dimensions,
            "analysis": "åŸºäºè§„åˆ™åˆ†é…æƒé‡ï¼Œå»ºè®®æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´"
        }
    else:
        # å…¨æ–°é…ç½®ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿
        default_dimensions = [
            {"name": "ä¸“ä¸šæŠ€èƒ½", "weight": 30, "description": f"{job_title}æ‰€éœ€çš„æ ¸å¿ƒä¸“ä¸šèƒ½åŠ›"},
            {"name": "æ²Ÿé€šåä½œ", "weight": 25, "description": "è·¨éƒ¨é—¨æ²Ÿé€šä¸å›¢é˜Ÿåä½œèƒ½åŠ›"},
            {"name": "é—®é¢˜è§£å†³", "weight": 20, "description": "åˆ†æé—®é¢˜å’Œè§£å†³é—®é¢˜çš„èƒ½åŠ›"},
            {"name": "å­¦ä¹ èƒ½åŠ›", "weight": 15, "description": "å¿«é€Ÿå­¦ä¹ æ–°çŸ¥è¯†å’Œé€‚åº”å˜åŒ–çš„èƒ½åŠ›"},
            {"name": "è´£ä»»å¿ƒ", "weight": 10, "description": "å·¥ä½œæ€åº¦å’Œè´£ä»»æ‹…å½“"},
        ]
        
        return {
            "dimensions": default_dimensions,
            "analysis": "åŸºäºé€šç”¨æ¨¡æ¿ç”Ÿæˆï¼Œå»ºè®®æ ¹æ®å²—ä½ç‰¹ç‚¹è°ƒæ•´"
        }
