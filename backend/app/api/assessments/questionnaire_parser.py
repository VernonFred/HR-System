"""é—®å·å¯¼å…¥è§£ææ¨¡å—.

æ”¯æŒä»å¤šç§æ ¼å¼å¯¼å…¥é—®å·ï¼š
- JSON æ–‡ä»¶
- Excel æ–‡ä»¶ (.xlsx)
- Word æ–‡ä»¶ (.docx)
- çº¯æ–‡æœ¬æ–‡ä»¶ (.txt)

V45: æ–°å¢AIæ™ºèƒ½è§£æåŠŸèƒ½
- ä¼˜å…ˆä½¿ç”¨AIè¯†åˆ«é¢˜ç›®ç±»å‹å’Œé€‰é¡¹
- è§„åˆ™åŒ¹é…ä½œä¸ºå…œåº•æ–¹æ¡ˆ
"""
import json
import re
import logging
import asyncio
from typing import Dict, List, Any, Optional, Tuple

logger = logging.getLogger(__name__)

# ========== V45: AIæ™ºèƒ½è§£æ ==========

# AIè§£ææç¤ºè¯ï¼ˆV45ä¼˜åŒ–ç‰ˆ - åŸºäºChatGPTå»ºè®®ï¼‰
AI_PARSE_PROMPT = """ä½ æ˜¯ä¸€å"é—®å·è§£æåŠ©æ‰‹"ï¼Œéœ€è¦æŠŠä¸€æ•´ä»½é—®å·çš„åŸå§‹æ–‡æœ¬è§£ææˆç»“æ„åŒ– JSONã€‚

ã€è¾“å…¥è¯´æ˜ã€‘
- è¾“å…¥æ˜¯ä¸€æ®µä» Word / ç½‘é¡µ / PDF ä¸­å¤åˆ¶å‡ºæ¥çš„é—®å·æ–‡æœ¬ã€‚
- é‡Œé¢å¯èƒ½åŒ…å«ï¼šé—®å·æ ‡é¢˜ã€è¯´æ˜æ–‡å­—ã€åˆ†èŠ‚æ ‡é¢˜ï¼ˆå¦‚"ä¸€ã€åŸºæœ¬ä¿¡æ¯"ï¼‰ã€é¢˜å·ï¼ˆ1. / 2. / ï¼ˆ1ï¼‰ï¼‰ã€é¢˜å‹æ ‡æ³¨ï¼ˆå•é€‰é¢˜ã€å¤šé€‰é¢˜ã€é‡è¡¨é¢˜ã€æ˜¯éé¢˜ã€å¡«ç©ºé¢˜ç­‰ï¼‰ã€‚
- æ¯é“é¢˜ä¸‹é¢å¯èƒ½æœ‰ A/B/C/D ç­‰é€‰é¡¹ï¼Œä¹Ÿå¯èƒ½æ˜¯å¼€æ”¾é¢˜æ²¡æœ‰é€‰é¡¹ã€‚

ã€ä½ çš„ä»»åŠ¡ã€‘
1. æ‰¾å‡ºé—®å·æ ‡é¢˜ï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œæ”¾åœ¨ "title" å­—æ®µé‡Œï¼›å¦‚æœæ²¡æœ‰æ ‡é¢˜ï¼Œtitle ç”¨ç©ºå­—ç¬¦ä¸² ""ã€‚
2. åªæå–çœŸæ­£çš„é¢˜ç›®ï¼Œå¿½ç•¥ä»¥ä¸‹å†…å®¹ï¼š
   - é—®å·å¼€å¤´æˆ–ç»“å°¾çš„è¯´æ˜æ–‡å­—ï¼ˆå¦‚"æ„Ÿè°¢å¡«å†™æœ¬é—®å·"ï¼‰ã€‚
   - åˆ†èŠ‚æ ‡é¢˜ï¼ˆå¦‚"ç¬¬ä¸€éƒ¨åˆ† åŸºæœ¬ä¿¡æ¯"ã€"ä¸€ã€å­¦ä¹ æƒ…å†µ"ï¼‰ã€‚
   - é¡µç ã€è£…é¥°æ€§æ–‡å­—ç­‰ã€‚
3. å¯¹æ¯ä¸€é“é¢˜ï¼Œè¾“å‡ºï¼š
   - textï¼šé¢˜ç›®æ­£æ–‡ï¼Œä¸è¦å¸¦é¢˜å·ï¼Œä¸è¦å¸¦"ï¼ˆå•é€‰é¢˜ï¼‰"ç­‰æ ‡ç­¾ã€‚
   - typeï¼šé¢˜ç›®ç±»å‹ï¼Œåªèƒ½æ˜¯ä»¥ä¸‹å‡ ç§ä¹‹ä¸€ï¼š
       - "single"   å•é€‰é¢˜ï¼ˆåªèƒ½é€‰ä¸€ä¸ªï¼‰
       - "multiple" å¤šé€‰é¢˜ï¼ˆå¯ä»¥é€‰å¤šä¸ªï¼‰
       - "rating"   é‡è¡¨/æ‰“åˆ†é¢˜ï¼ˆå¦‚ 1â€“5 åˆ†ã€"éå¸¸ä¸åŒæ„â€“éå¸¸åŒæ„"ï¼‰
       - "yesno"    æ˜¯éé¢˜ / åˆ¤æ–­é¢˜ï¼ˆä¾‹å¦‚"æ˜¯/å¦"ã€"å¯¹/é”™"ï¼‰
       - "choice"   äºŒé€‰ä¸€é¢˜ï¼ˆä¸¤ä¸ªè¾ƒé•¿çš„é€‰é¡¹ï¼Œå¦‚A/Bä¸¤ç§è§‚ç‚¹ï¼‰
       - "text"     æ–‡æœ¬å¼€æ”¾é¢˜ï¼ˆå¡«ç©ºã€ç®€ç­”ï¼Œæ²¡æœ‰å›ºå®šé€‰é¡¹ï¼‰
       - "textarea" å¤šè¡Œæ–‡æœ¬é¢˜ï¼ˆéœ€è¦è¯¦ç»†æè¿°çš„å¼€æ”¾é¢˜ï¼‰
   - optionsï¼šä¸€ä¸ªå¯¹è±¡æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å« text å’Œ score å­—æ®µï¼š
       - å¯¹äº single / multiple / yesno / choiceï¼Œå¡«å…¥æ‰€æœ‰é€‰é¡¹ï¼›
       - å¯¹äº ratingï¼Œå¦‚æœé¢˜ç›®ç»™å‡ºäº†æ–‡å­—é”šç‚¹ï¼ˆå¦‚"1 éå¸¸ä¸åŒæ„â€¦5 éå¸¸åŒæ„"ï¼‰ï¼Œä¹Ÿåˆ—å‡ºï¼›
       - å¯¹äº text / textareaï¼Œæ²¡æœ‰é€‰é¡¹æ—¶ï¼Œoptions ç”¨ç©ºæ•°ç»„ []ã€‚
   - scaleï¼ˆå¯é€‰ï¼‰ï¼šå¦‚æœæ˜¯ rating é¢˜ç›®ï¼Œå¢åŠ é‡è¡¨èŒƒå›´ä¿¡æ¯ï¼š
       - "scale": {{"min": 1, "max": 5, "minLabel": "éå¸¸ä¸åŒæ„", "maxLabel": "éå¸¸åŒæ„"}}

ã€é¢˜å‹è¯†åˆ«è§„åˆ™ï¼ˆè¯·ä¸¥æ ¼éµå®ˆï¼‰ã€‘
1. å¦‚æœé¢˜å¹²æˆ–æ‹¬å·é‡Œæ˜ç¡®å†™äº†"å•é€‰é¢˜""å•é€‰""è¯·é€‰æ‹©ä¸€é¡¹"ï¼Œåˆ™ type = "single"ã€‚
2. å¦‚æœé¢˜å¹²æˆ–æ‹¬å·é‡Œå†™äº†"å¤šé€‰é¢˜""å¤šé€‰""å¯å¤šé€‰""è‡³å°‘é€‰æ‹©ä¸¤é¡¹"ç­‰ï¼Œåˆ™ type = "multiple"ã€‚
3. å¦‚æœå‡ºç°"åœ¨ 1â€“5 åˆ†ä¸­é€‰æ‹©""è¯·æŒ‰ 1~7 åˆ†æ‰“åˆ†""éå¸¸ä¸åŒæ„ â€“ éå¸¸åŒæ„"ç­‰è¯„åˆ†/é‡è¡¨æè¿°ï¼Œåˆ™ type = "rating"ã€‚
4. å¦‚æœé€‰é¡¹åªæœ‰"æ˜¯/å¦""å¯¹/é”™""æ˜¯çš„/ä¸æ˜¯"ï¼Œæˆ–è€…é¢˜å¹²é‡Œå†™äº†"æ˜¯å¦â€¦â€¦"ï¼Œå¹¶ä¸”æ²¡æœ‰æ›´å¤æ‚çš„é€‰é¡¹ï¼Œåˆ™ type = "yesno"ã€‚
5. å¦‚æœåªæœ‰ä¸¤ä¸ªé€‰é¡¹ï¼Œä¸”æ¯ä¸ªé€‰é¡¹å†…å®¹è¾ƒé•¿ï¼ˆè¶…è¿‡15ä¸ªå­—ï¼‰ï¼Œåˆ™ type = "choice"ã€‚
6. å¦‚æœæ˜¯"ç®€è¦è¯´æ˜â€¦â€¦""è¯·å¡«å†™â€¦â€¦""å…¶ä»–æƒ…å†µè¯·å†™å‡º""è¯·æè¿°â€¦â€¦"ï¼Œä¸”æ²¡æœ‰é€‰é¡¹ï¼š
   - å¦‚æœéœ€è¦è¯¦ç»†æè¿°ï¼ˆå¦‚"è¯·è¯¦ç»†è¯´æ˜"ï¼‰ï¼Œtype = "textarea"ï¼›
   - å…¶ä»–ç®€çŸ­å¡«å†™ï¼Œtype = "text"ã€‚
7. é€‰é¡¹å‰é¢çš„åºå·æˆ–å­—æ¯ï¼ˆå¦‚"1."ã€"A."ã€"Bã€"ç­‰ï¼‰è¯·å»æ‰ï¼Œåªä¿ç•™é€‰é¡¹å†…å®¹æœ¬èº«ã€‚

ã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘
- ä¸¥æ ¼è¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å«ä»»ä½•é¢å¤–è¯´æ˜æ–‡å­—ï¼Œä¸è¦ä½¿ç”¨ Markdown ä»£ç å—ã€‚
- å­—æ®µç»“æ„å›ºå®šä¸ºï¼š

{{
  "title": "é—®å·æ ‡é¢˜ï¼ˆå­—ç¬¦ä¸²ï¼‰",
  "description": "é—®å·æè¿°ï¼ˆå¦‚æœæœ‰ï¼‰",
  "questions": [
    {{
      "text": "é¢˜ç›®å†…å®¹ï¼ˆå­—ç¬¦ä¸²ï¼‰",
      "type": "single/multiple/rating/yesno/choice/text/textarea ä¹‹ä¸€",
      "options": [
        {{"text": "é€‰é¡¹å†…å®¹", "score": 0}}
      ],
      "scale": {{
        "min": 1,
        "max": 5,
        "minLabel": "æœ€ä½æ ‡ç­¾",
        "maxLabel": "æœ€é«˜æ ‡ç­¾"
      }}
    }}
  ]
}}

ã€å¾…è§£æçš„é—®å·åŸæ–‡ã€‘
{content}"""


async def _ai_parse_content(content: str) -> Optional[Dict[str, Any]]:
    """ä½¿ç”¨AIè§£æé—®å·å†…å®¹."""
    try:
        # å¯¼å…¥AIå®¢æˆ·ç«¯
        from app.core.ai.portrait_router import call_portrait_model
        
        prompt = AI_PARSE_PROMPT.format(content=content[:8000])  # é™åˆ¶å†…å®¹é•¿åº¦
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®å·è§£æåŠ©æ‰‹ï¼Œåªè¾“å‡ºJSONæ ¼å¼çš„ç»“æœã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        logger.info("ğŸ¤– å¼€å§‹AIæ™ºèƒ½è§£æé—®å·...")
        
        result = await call_portrait_model(
            messages=messages,
            level="normal",  # ä½¿ç”¨æ™®é€šçº§åˆ«å³å¯
            max_tokens=4096,
            temperature=0.1,  # ä½æ¸©åº¦ç¡®ä¿ç¨³å®šè¾“å‡º
        )
        
        # æå–AIè¿”å›çš„å†…å®¹
        ai_content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
        
        if not ai_content:
            logger.warning("AIè¿”å›å†…å®¹ä¸ºç©º")
            return None
        
        # å°è¯•æå–JSON
        json_match = re.search(r'```json\s*(.*?)\s*```', ai_content, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # å°è¯•ç›´æ¥è§£æ
            json_str = ai_content.strip()
            # ç§»é™¤å¯èƒ½çš„å‰åç¼€
            if json_str.startswith("```"):
                json_str = re.sub(r'^```\w*\n?', '', json_str)
                json_str = re.sub(r'\n?```$', '', json_str)
        
        parsed = json.loads(json_str)
        logger.info(f"âœ… AIè§£ææˆåŠŸï¼Œè¯†åˆ«åˆ° {len(parsed.get('questions', []))} é“é¢˜ç›®")
        return parsed
        
    except json.JSONDecodeError as e:
        logger.warning(f"AIè¿”å›çš„JSONè§£æå¤±è´¥: {e}")
        return None
    except Exception as e:
        logger.warning(f"AIè§£æå¤±è´¥: {e}")
        return None


def _convert_ai_result_to_questions(ai_result: Dict[str, Any]) -> Tuple[Dict[str, Any], List[Dict[str, Any]]]:
    """å°†AIè§£æç»“æœè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼."""
    metadata = {
        "name": ai_result.get("title") or "å¯¼å…¥çš„é—®å·",
        "description": ai_result.get("description") or "",
        "estimated_minutes": 15,
    }
    
    questions = []
    for i, q in enumerate(ai_result.get("questions", [])):
        q_type = q.get("type", "single")
        
        question = {
            "id": f"q{i+1}",
            "text": q.get("text", ""),
            "type": q_type,
            "options": [],
            "required": True,
        }
        
        # å¤„ç†é€‰é¡¹
        for j, opt in enumerate(q.get("options", [])):
            if isinstance(opt, str):
                question["options"].append({
                    "id": f"q{i+1}_opt{j}",
                    "text": opt,
                    "score": 0
                })
            elif isinstance(opt, dict):
                question["options"].append({
                    "id": f"q{i+1}_opt{j}",
                    "text": opt.get("text", ""),
                    "score": opt.get("score", 0)
                })
        
        # V45: å¤„ç†é‡è¡¨é¢˜çš„scaleä¿¡æ¯
        if q_type == "rating" and q.get("scale"):
            scale = q.get("scale")
            question["scale"] = {
                "min": scale.get("min", 1),
                "max": scale.get("max", 5),
                "minLabel": scale.get("minLabel", "æœ€ä½"),
                "maxLabel": scale.get("maxLabel", "æœ€é«˜"),
            }
        
        questions.append(question)
    
    return metadata, questions


async def parse_questionnaire_file_async(
    content: bytes,
    filename: str,
    content_type: str,
    use_ai: bool = True
) -> Tuple[Dict[str, Any], List[Dict[str, Any]]]:
    """
    å¼‚æ­¥è§£æé—®å·æ–‡ä»¶ï¼ˆæ”¯æŒAIæ™ºèƒ½è§£æï¼‰.
    
    Args:
        content: æ–‡ä»¶å†…å®¹
        filename: æ–‡ä»¶å
        content_type: å†…å®¹ç±»å‹
        use_ai: æ˜¯å¦ä½¿ç”¨AIè§£æï¼ˆé»˜è®¤Trueï¼‰
    
    Returns:
        Tuple[é—®å·å…ƒæ•°æ®, é¢˜ç›®åˆ—è¡¨]
    """
    # å…ˆæå–æ–‡æœ¬å†…å®¹
    text_content = _extract_text_content(content, filename)
    
    # V45: ä¼˜å…ˆå°è¯•AIè§£æ
    if use_ai and text_content:
        try:
            ai_result = await _ai_parse_content(text_content)
            if ai_result and ai_result.get("questions"):
                logger.info("âœ… ä½¿ç”¨AIè§£æç»“æœ")
                return _convert_ai_result_to_questions(ai_result)
        except Exception as e:
            logger.warning(f"AIè§£æå¼‚å¸¸ï¼Œä½¿ç”¨è§„åˆ™åŒ¹é…: {e}")
    
    # å…œåº•ï¼šä½¿ç”¨è§„åˆ™åŒ¹é…
    logger.info("ğŸ“‹ ä½¿ç”¨è§„åˆ™åŒ¹é…è§£æ")
    return parse_questionnaire_file(content, filename, content_type)


def _extract_text_content(content: bytes, filename: str) -> str:
    """ä»æ–‡ä»¶ä¸­æå–çº¯æ–‡æœ¬å†…å®¹ï¼ˆä¾›AIè§£æä½¿ç”¨ï¼‰."""
    filename_lower = filename.lower()
    
    try:
        if filename_lower.endswith('.json'):
            return content.decode('utf-8')
        
        elif filename_lower.endswith('.xlsx') or filename_lower.endswith('.xls'):
            try:
                import openpyxl
                from io import BytesIO
                wb = openpyxl.load_workbook(BytesIO(content), data_only=True)
                ws = wb.active
                lines = []
                for row in ws.iter_rows(values_only=True):
                    if row and row[0]:
                        lines.append(str(row[0]).strip())
                return '\n'.join(lines)
            except Exception:
                return ""
        
        elif filename_lower.endswith('.docx'):
            try:
                from docx import Document
                from io import BytesIO
                doc = Document(BytesIO(content))
                return '\n'.join(para.text.strip() for para in doc.paragraphs if para.text.strip())
            except Exception:
                return ""
        
        elif filename_lower.endswith('.txt'):
            try:
                return content.decode('utf-8')
            except UnicodeDecodeError:
                return content.decode('gbk', errors='ignore')
        
        return ""
    except Exception as e:
        logger.warning(f"æå–æ–‡æœ¬å†…å®¹å¤±è´¥: {e}")
        return ""


def parse_questionnaire_file(
    content: bytes,
    filename: str,
    content_type: str
) -> Tuple[Dict[str, Any], List[Dict[str, Any]]]:
    """
    è§£æä¸Šä¼ çš„é—®å·æ–‡ä»¶.
    
    Returns:
        Tuple[é—®å·å…ƒæ•°æ®, é¢˜ç›®åˆ—è¡¨]
    """
    filename_lower = filename.lower()
    
    if filename_lower.endswith('.json'):
        return _parse_json(content)
    elif filename_lower.endswith('.xlsx') or filename_lower.endswith('.xls'):
        return _parse_excel(content)
    elif filename_lower.endswith('.docx'):
        return _parse_word(content)
    elif filename_lower.endswith('.txt'):
        return _parse_text(content)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {filename}")


def _parse_json(content: bytes) -> Tuple[Dict[str, Any], List[Dict[str, Any]]]:
    """è§£æJSONæ ¼å¼é—®å·."""
    try:
        data = json.loads(content.decode('utf-8'))
    except json.JSONDecodeError as e:
        raise ValueError(f"JSONæ ¼å¼é”™è¯¯: {str(e)}")
    
    # æ”¯æŒå¤šç§JSONç»“æ„
    if isinstance(data, list):
        # ç›´æ¥æ˜¯é¢˜ç›®åˆ—è¡¨
        return {}, _normalize_questions(data)
    
    if isinstance(data, dict):
        # æ ‡å‡†ç»“æ„: { "title": "...", "questions": [...] }
        metadata = {
            "name": data.get("title") or data.get("name") or "å¯¼å…¥çš„é—®å·",
            "description": data.get("description") or data.get("desc") or "",
            "estimated_minutes": data.get("estimated_minutes") or data.get("duration") or 15,
        }
        
        questions = data.get("questions") or data.get("items") or []
        return metadata, _normalize_questions(questions)
    
    raise ValueError("æ— æ³•è¯†åˆ«çš„JSONç»“æ„")


def _parse_excel(content: bytes) -> Tuple[Dict[str, Any], List[Dict[str, Any]]]:
    """è§£æExcelæ ¼å¼é—®å·."""
    try:
        import openpyxl
        from io import BytesIO
    except ImportError:
        raise ValueError("éœ€è¦å®‰è£…openpyxlåº“æ¥è§£æExcelæ–‡ä»¶")
    
    wb = openpyxl.load_workbook(BytesIO(content), data_only=True)
    ws = wb.active
    
    questions = []
    metadata = {"name": "å¯¼å…¥çš„é—®å·", "description": "", "estimated_minutes": 15}
    
    # å°è¯•ä»ç¬¬ä¸€è¡Œè·å–æ ‡é¢˜
    first_row = [cell.value for cell in ws[1]]
    if first_row and first_row[0] and not _looks_like_question(str(first_row[0])):
        metadata["name"] = str(first_row[0])
        start_row = 2
    else:
        start_row = 1
    
    # è§£æé¢˜ç›®
    current_question = None
    for row in ws.iter_rows(min_row=start_row, values_only=True):
        if not row or not row[0]:
            continue
        
        text = str(row[0]).strip()
        if not text:
            continue
        
        # åˆ¤æ–­æ˜¯é¢˜ç›®è¿˜æ˜¯é€‰é¡¹
        if _looks_like_question(text):
            if current_question:
                questions.append(current_question)
            current_question = _create_question_from_text(text, len(questions) + 1)
        elif current_question and _looks_like_option(text):
            _add_option_to_question(current_question, text)
    
    if current_question:
        questions.append(current_question)
    
    # V45: åå¤„ç† - æ ¹æ®é€‰é¡¹æ™ºèƒ½æ¨æ–­é¢˜ç›®ç±»å‹
    questions = _post_process_questions(questions)
    
    return metadata, questions


def _parse_word(content: bytes) -> Tuple[Dict[str, Any], List[Dict[str, Any]]]:
    """è§£æWordæ ¼å¼é—®å·."""
    try:
        from docx import Document
        from io import BytesIO
    except ImportError:
        raise ValueError("éœ€è¦å®‰è£…python-docxåº“æ¥è§£æWordæ–‡ä»¶")
    
    doc = Document(BytesIO(content))
    
    metadata = {"name": "å¯¼å…¥çš„é—®å·", "description": "", "estimated_minutes": 15}
    questions = []
    current_question = None
    
    for para in doc.paragraphs:
        text = para.text.strip()
        if not text:
            continue
        
        # ç¬¬ä¸€æ®µå¯èƒ½æ˜¯æ ‡é¢˜
        if not questions and not current_question and not _looks_like_question(text):
            metadata["name"] = text
            continue
        
        if _looks_like_question(text):
            if current_question:
                questions.append(current_question)
            current_question = _create_question_from_text(text, len(questions) + 1)
        elif current_question and _looks_like_option(text):
            _add_option_to_question(current_question, text)
    
    if current_question:
        questions.append(current_question)
    
    # V45: åå¤„ç† - æ ¹æ®é€‰é¡¹æ™ºèƒ½æ¨æ–­é¢˜ç›®ç±»å‹
    questions = _post_process_questions(questions)
    
    return metadata, questions


def _parse_text(content: bytes) -> Tuple[Dict[str, Any], List[Dict[str, Any]]]:
    """è§£æçº¯æ–‡æœ¬æ ¼å¼é—®å·."""
    try:
        text = content.decode('utf-8')
    except UnicodeDecodeError:
        text = content.decode('gbk', errors='ignore')
    
    lines = text.strip().split('\n')
    
    metadata = {"name": "å¯¼å…¥çš„é—®å·", "description": "", "estimated_minutes": 15}
    questions = []
    current_question = None
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # ç¬¬ä¸€è¡Œå¯èƒ½æ˜¯æ ‡é¢˜
        if not questions and not current_question and not _looks_like_question(line):
            metadata["name"] = line
            continue
        
        if _looks_like_question(line):
            if current_question:
                questions.append(current_question)
            current_question = _create_question_from_text(line, len(questions) + 1)
        elif current_question and _looks_like_option(line):
            _add_option_to_question(current_question, line)
    
    if current_question:
        questions.append(current_question)
    
    # V45: åå¤„ç† - æ ¹æ®é€‰é¡¹æ™ºèƒ½æ¨æ–­é¢˜ç›®ç±»å‹
    questions = _post_process_questions(questions)
    
    return metadata, questions


def _post_process_questions(questions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """V45: åå¤„ç†é¢˜ç›®åˆ—è¡¨ï¼Œæ ¹æ®é€‰é¡¹æ™ºèƒ½æ¨æ–­é¢˜ç›®ç±»å‹."""
    for q in questions:
        options = q.get("options", [])
        option_count = len(options)
        current_type = q.get("type", "single")
        
        # å¦‚æœå·²ç»æ˜ç¡®è¯†åˆ«äº†ç±»å‹ï¼ˆéé»˜è®¤å•é€‰ï¼‰ï¼Œè·³è¿‡
        if current_type != "single":
            continue
        
        # æ ¹æ®é€‰é¡¹æ•°é‡å’Œå†…å®¹æ¨æ–­ç±»å‹
        if option_count == 0:
            # æ— é€‰é¡¹ â†’ æ–‡æœ¬é¢˜
            q["type"] = "text"
        elif option_count == 2:
            # 2ä¸ªé€‰é¡¹ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯æ˜¯éé¢˜
            opt_texts = [opt.get("text", "").lower() for opt in options]
            yesno_pairs = [
                ("æ˜¯", "å¦"), ("å¯¹", "é”™"), ("æœ‰", "æ²¡æœ‰"), ("ä¼š", "ä¸ä¼š"),
                ("åŒæ„", "ä¸åŒæ„"), ("æ»¡æ„", "ä¸æ»¡æ„"), ("yes", "no"),
                ("true", "false"), ("æ­£ç¡®", "é”™è¯¯")
            ]
            is_yesno = any(
                (p[0] in opt_texts[0] and p[1] in opt_texts[1]) or
                (p[1] in opt_texts[0] and p[0] in opt_texts[1])
                for p in yesno_pairs
            )
            
            if is_yesno:
                q["type"] = "yesno"
            else:
                # æ£€æŸ¥é€‰é¡¹é•¿åº¦ï¼Œè¾ƒé•¿çš„å¯èƒ½æ˜¯äºŒé€‰ä¸€
                avg_len = sum(len(opt.get("text", "")) for opt in options) / 2
                if avg_len > 15:
                    q["type"] = "choice"
                # å¦åˆ™ä¿æŒå•é€‰
        elif option_count > 6:
            # é€‰é¡¹è¿‡å¤šï¼Œå¯èƒ½æ˜¯å¤šé€‰é¢˜
            q["type"] = "multiple"
    
    return questions


def _looks_like_question(text: str) -> bool:
    """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦åƒä¸€ä¸ªé¢˜ç›®."""
    # å¸¸è§çš„é¢˜ç›®å¼€å¤´æ¨¡å¼
    patterns = [
        r'^[\d]+[\.ã€\)ï¼‰]\s*',  # 1. æˆ– 1ã€æˆ– 1) æˆ– 1ï¼‰
        r'^Q[\d]+[\.ã€:ï¼š]?\s*',  # Q1. æˆ– Q1
        r'^ç¬¬[\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[é¢˜é“][\.ã€:ï¼š]?\s*',  # ç¬¬1é¢˜
        r'^[\(ï¼ˆ][\d]+[\)ï¼‰]\s*',  # (1) æˆ– ï¼ˆ1ï¼‰
        r'^é¢˜ç›®[\d]*[\.ã€:ï¼š]?\s*',  # é¢˜ç›®1. æˆ– é¢˜ç›®ï¼š
    ]
    
    for pattern in patterns:
        if re.match(pattern, text, re.IGNORECASE):
            return True
    
    # åŒ…å«é—®å·çš„å¯èƒ½æ˜¯é¢˜ç›®
    if '?' in text or 'ï¼Ÿ' in text:
        return True
    
    # V45: å¢å¼ºè¯†åˆ« - å¸¸è§çš„é¢˜ç›®å¼€å¤´è¯
    question_starters = ['è¯·é—®', 'æ‚¨è®¤ä¸º', 'ä½ è®¤ä¸º', 'è¯·é€‰æ‹©', 'è¯·è¯„ä»·', 'æ‚¨å¯¹', 'ä½ å¯¹', 
                         'ä»¥ä¸‹', 'ä¸‹åˆ—', 'å…³äº', 'å¯¹äº', 'åœ¨æ‚¨çœ‹æ¥', 'åœ¨ä½ çœ‹æ¥']
    for starter in question_starters:
        if text.startswith(starter):
            return True
    
    return False


def _looks_like_option(text: str) -> bool:
    """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦åƒä¸€ä¸ªé€‰é¡¹."""
    # å¸¸è§çš„é€‰é¡¹å¼€å¤´æ¨¡å¼
    patterns = [
        r'^[A-Za-z][\.ã€\)ï¼‰:ï¼š]\s*',  # A. æˆ– Aã€æˆ– A) æˆ– Aï¼š
        r'^[\(ï¼ˆ][A-Za-z][\)ï¼‰]\s*',  # (A) æˆ– ï¼ˆAï¼‰
        r'^[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]\s*',  # åœ†åœˆæ•°å­—
        r'^[\-\*â€¢Â·]\s*',  # åˆ—è¡¨ç¬¦å·
        r'^é€‰é¡¹[A-Za-zä¸€äºŒä¸‰å››äº”å…­][\.ã€:ï¼š]?\s*',  # é€‰é¡¹A. æˆ– é€‰é¡¹ä¸€
    ]
    
    for pattern in patterns:
        if re.match(pattern, text):
            return True
    
    # V45: çŸ­æ–‡æœ¬ï¼ˆ<40å­—ï¼‰ä¸”ä¸åƒé¢˜ç›®ï¼Œå¯èƒ½æ˜¯é€‰é¡¹
    if len(text) < 40 and not _looks_like_question(text):
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§çš„é€‰é¡¹å†…å®¹
        option_keywords = ['éå¸¸', 'æ¯”è¾ƒ', 'ä¸€èˆ¬', 'ä¸å¤ª', 'å®Œå…¨', 'åŒæ„', 'ä¸åŒæ„',
                          'æ»¡æ„', 'ä¸æ»¡æ„', 'ç»å¸¸', 'å¶å°”', 'ä»ä¸', 'æ€»æ˜¯', 'æœ‰æ—¶']
        for kw in option_keywords:
            if text.startswith(kw):
                return True
    
    return False


def _create_question_from_text(text: str, index: int) -> Dict[str, Any]:
    """ä»æ–‡æœ¬åˆ›å»ºé¢˜ç›®ç»“æ„."""
    # ç§»é™¤é¢˜å·å‰ç¼€
    clean_text = re.sub(r'^[\d]+[\.ã€\)ï¼‰]\s*', '', text)
    clean_text = re.sub(r'^Q[\d]+[\.ã€:ï¼š]?\s*', '', clean_text, flags=re.IGNORECASE)
    clean_text = re.sub(r'^ç¬¬[\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[é¢˜é“][\.ã€:ï¼š]?\s*', '', clean_text)
    clean_text = re.sub(r'^[\(ï¼ˆ][\d]+[\)ï¼‰]\s*', '', clean_text)
    clean_text = re.sub(r'^é¢˜ç›®[\d]*[\.ã€:ï¼š]?\s*', '', clean_text)
    
    # åˆ¤æ–­é¢˜ç›®ç±»å‹ï¼ˆV45å¢å¼ºï¼‰
    q_type = "single"  # é»˜è®¤å•é€‰
    
    # æ£€æµ‹å¤šé€‰é¢˜
    if any(kw in text for kw in ['å¤šé€‰', 'å¯å¤šé€‰', 'å¤šé¡¹é€‰æ‹©', 'é€‰æ‹©æ‰€æœ‰', 'å¯ä»¥é€‰æ‹©å¤šä¸ª', 'è‡³å°‘é€‰æ‹©']):
        q_type = "multiple"
    
    # æ£€æµ‹å¡«ç©ºé¢˜/æ–‡æœ¬é¢˜
    elif any(kw in text for kw in ['è¯·å¡«å†™', 'è¯·è¾“å…¥', 'ç®€ç­”', 'å¡«ç©º', 'è¯·æè¿°', 'è¯·è¯´æ˜', 
                                    'è¯·å†™å‡º', 'è¯·åˆ—ä¸¾', 'æ‚¨çš„å»ºè®®', 'ä½ çš„å»ºè®®', 'å…¶ä»–æ„è§']):
        q_type = "text"
    
    # æ£€æµ‹å¤šè¡Œæ–‡æœ¬é¢˜
    elif any(kw in text for kw in ['è¯¦ç»†æè¿°', 'è¯¦ç»†è¯´æ˜', 'è¯·è¯¦ç»†', 'å…·ä½“è¯´æ˜', 'è¡¥å……è¯´æ˜']):
        q_type = "textarea"
    
    # æ£€æµ‹è¯„åˆ†é¢˜/é‡è¡¨é¢˜
    elif any(kw in text for kw in ['è¯„åˆ†', 'æ‰“åˆ†', 'åˆ†æ•°', '1-5', '1-10', 'è¯„ä»·ç¨‹åº¦', 
                                    'æ»¡æ„åº¦', 'è®¤åŒç¨‹åº¦', 'ä»1åˆ°', 'é‡è¡¨']):
        q_type = "rating"
    
    # æ£€æµ‹æ˜¯éé¢˜
    elif any(kw in text for kw in ['æ˜¯å¦', 'æ˜¯ä¸æ˜¯', 'æœ‰æ²¡æœ‰', 'å¯¹ä¸å¯¹', 'åŒä¸åŒæ„']):
        q_type = "yesno"
    
    return {
        "id": f"q{index}",
        "text": clean_text.strip(),
        "type": q_type,
        "options": [],
        "required": True,
        "score": 0 if q_type in ["text", "textarea", "rating"] else None
    }


def _add_option_to_question(question: Dict[str, Any], text: str) -> None:
    """å‘é¢˜ç›®æ·»åŠ é€‰é¡¹."""
    # ç§»é™¤é€‰é¡¹å‰ç¼€
    clean_text = re.sub(r'^[A-Za-z][\.ã€\)ï¼‰:ï¼š]\s*', '', text)
    clean_text = re.sub(r'^[\(ï¼ˆ][A-Za-z][\)ï¼‰]\s*', '', clean_text)
    clean_text = re.sub(r'^[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]\s*', '', clean_text)
    clean_text = re.sub(r'^[\-\*â€¢Â·]\s*', '', clean_text)
    
    option_index = len(question["options"])
    
    # æ£€æµ‹æ˜¯å¦æœ‰åˆ†æ•°æ ‡è®°
    score = 0
    score_match = re.search(r'[\(ï¼ˆ](\d+)åˆ†[\)ï¼‰]', clean_text)
    if score_match:
        score = int(score_match.group(1))
        clean_text = re.sub(r'[\(ï¼ˆ]\d+åˆ†[\)ï¼‰]', '', clean_text)
    
    question["options"].append({
        "id": f"{question['id']}_opt{option_index}",
        "text": clean_text.strip(),
        "score": score
    })


def _normalize_questions(questions: List[Any]) -> List[Dict[str, Any]]:
    """æ ‡å‡†åŒ–é¢˜ç›®åˆ—è¡¨æ ¼å¼."""
    normalized = []
    
    for i, q in enumerate(questions):
        if isinstance(q, str):
            # çº¯æ–‡æœ¬é¢˜ç›®
            normalized.append({
                "id": f"q{i+1}",
                "text": q,
                "type": "single",
                "options": [],
                "required": True
            })
        elif isinstance(q, dict):
            # å­—å…¸æ ¼å¼é¢˜ç›®
            normalized.append({
                "id": q.get("id") or f"q{i+1}",
                "text": q.get("text") or q.get("question") or q.get("title") or "",
                "type": q.get("type") or "single",
                "options": _normalize_options(q.get("options") or q.get("choices") or []),
                "required": q.get("required", True),
                "score": q.get("score", 0)
            })
    
    return normalized


def _normalize_options(options: List[Any]) -> List[Dict[str, Any]]:
    """æ ‡å‡†åŒ–é€‰é¡¹åˆ—è¡¨æ ¼å¼."""
    normalized = []
    
    for i, opt in enumerate(options):
        if isinstance(opt, str):
            normalized.append({
                "id": f"opt{i}",
                "text": opt,
                "score": 0
            })
        elif isinstance(opt, dict):
            normalized.append({
                "id": opt.get("id") or f"opt{i}",
                "text": opt.get("text") or opt.get("label") or "",
                "score": opt.get("score") or opt.get("value") or 0
            })
    
    return normalized

