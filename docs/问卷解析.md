可以的，我们把这件事分两步搞定：
1）写一个更“聪明”的提示词，让大模型能稳定识别题目和选项；
2）顺手把你的函数伪代码也优化一下，方便你直接丢给 Cursor 改。

⸻

一、推荐的 AI 解析提示词（直接替换你现在的 prompt）

async def ai_parse_questionnaire(content: str) -> dict:
    prompt = f"""
你是一名“问卷解析助手”，需要把一整份问卷的原始文本解析成结构化 JSON。

【输入说明】
- 输入是一段从 Word / 网页 / PDF 中复制出来的问卷文本。
- 里面可能包含：问卷标题、说明文字、分节标题（如“一、基本信息”）、题号（1. / 2. / （1））、题型标注（单选题、多选题、量表题、是非题、填空题等）。
- 每道题下面可能有 A/B/C/D 等选项，也可能是开放题没有选项。

【你的任务】
1. 找出问卷标题（如果有），放在 "title" 字段里；如果没有标题，title 用空字符串 ""。
2. 只提取真正的题目，忽略以下内容：
   - 问卷开头或结尾的说明文字（如“感谢填写本问卷”）。
   - 分节标题（如“第一部分 基本信息”、“一、学习情况”）。
   - 页码、装饰性文字等。
3. 对每一道题，输出：
   - text：题目正文，不要带题号，不要带“（单选题）”等标签。
   - type：题目类型，只能是以下几种之一：
       - "single"   单选题（只能选一个）
       - "multiple" 多选题（可以选多个）
       - "rating"   量表/打分题（如 1–5 分、“非常不同意–非常同意”）
       - "yesno"    是非题 / 判断题（例如“是/否”、“对/错”）
       - "text"     文本开放题（填空、简答，没有固定选项）
       - "info"     纯信息填写题（如“姓名：”“学校：”，没有选项，用户自己填）
   - options：一个字符串数组：
       - 对于 single / multiple / yesno，填入所有选项内容；
       - 对于 rating，如果题目本身给出了文字锚点（例如“1 非常不同意…5 非常同意”），也作为 options 依次列出；
       - 对于 text / info，没有选项时，options 用空数组 []。
   - extra（可选）：如果你能识别到量表范围，建议加上：
       - 对 rating 题目，增加字段：
         "extra": {{
           "scale_min": 整数,   // 如 1
           "scale_max": 整数,   // 如 5
           "scale_description": "例如：1=非常不同意，5=非常同意"
         }}
       - 其他题型暂时可以不加 extra。

【题型识别规则（请遵守）】
1. 如果题干或括号里明确写了“单选题”“单选”“请选择一项”，则 type = "single"。
2. 如果题干或括号里写了“多选题”“多选”“可多选”“至少选择两项”等，则 type = "multiple"。
3. 如果出现“在 1–5 分中选择”“请按 1~7 分打分”“非常不同意 – 非常同意”等评分/量表描述，则 type = "rating"。
4. 如果选项只有“是/否”“对/错”“是的/不是”，或者题干里写了“是否……”，并且没有更复杂的选项，则 type = "yesno"。
5. 如果是“简要说明……”“请填写……”“其他情况请写出”“请描述……”，且没有选项，则：
   - 如果是类似“姓名、手机号、年龄、班级”这种基本信息字段，type = "info"；
   - 其他开放问题（例如“你对本课程的建议是什么？”）type = "text"。
6. 选项前面的序号或字母（如“1.”、“A.”、“B、”等）请去掉，只保留选项内容本身。

【输出格式要求】
- 严格输出一个 JSON 对象，不要包含任何额外说明文字，不要使用 Markdown 代码块。
- 字段结构固定为：

{{
  "title": "问卷标题（字符串）",
  "questions": [
    {{
      "text": "题目内容（字符串）",
      "type": "single/multiple/rating/yesno/text/info 之一",
      "options": ["选项1", "选项2"],
      "extra": {{
        // 可选字段，无则省略或使用 {{}}
      }}
    }}
  ]
}}

【待解析的问卷原文】
{content}
    """
    response = await call_llm(prompt)
    # 建议这里再做一次 json 解析和容错处理
    data = json.loads(response)
    return data

上面这段你可以直接丢给 Cursor，让它改你原来的函数。
核心是：把规则说清楚 + 要求只返回 JSON。

⸻

二、代码层面的小建议（可让 Cursor 一起改）
	1.	强制 JSON 返回（减少模型乱说话）
	•	如果你用的是 OpenAI / Qwen 这类支持 response_format=json 的接口，可以在 call_llm 里统一加上强制 JSON 返回，减少报错。
	2.	增加一层容错解析
例如：

import json
import re

def safe_parse_json(raw: str) -> dict:
    # 如果模型返回里不小心带了 markdown 代码块，先去掉 ``` 包裹
    cleaned = re.sub(r"^```json|^```|```$", "", raw.strip(), flags=re.IGNORECASE|re.MULTILINE)
    return json.loads(cleaned)

async def ai_parse_questionnaire(content: str) -> dict:
    prompt = f"""...上面的长提示词..."""
    raw = await call_llm(prompt)
    return safe_parse_json(raw)


⸻

